\newpage
{\Huge \bf Abstract}
\vspace{24pt} 

This project investigates the use of model-based reinforcement learning (RL) in the domain of computer systems, specifically, that of optimising deep learning models by applying transformations to the network which is represented as a graph. Reducing the hardware resource requirements is a challenging research problem which is still under active development to discover optimal heuristic rules. In this work, we investigated the use of RL agents that can learn to perform optimal actions, often without the need of expert human heuristics to achieve a high level of performance. Recent work has aimed to apply reinforcement learning to computer systems with some success, especially with using model-free RL techniques. However, more recently, model-based methods has seen an increased focus of research as model-based reinforcement learning can be used to learn a model of the environment, that can be leveraged to train an agent inside the learned world-model---increasing sample efficiency. Furthermore, when using a hallucinogenic world model as the environment, rollouts can occur safely in parallel and, especially in systems environments, it circumvents the possible latency impact of stepping a system environment that can take orders of magnitude longer to perform an action compared to a video game emulator. This dissertation examines both the prior work for optimising deep learning models and the applicability of reinforcement learning to the problem.

\vspace*{\fill}
