\newpage
{\Huge \bf Abstract}
\vspace{24pt} 

This project investigates the use of model-based reinforcement learning (RL) in the domain of computer systems, specifically, that of optimising deep learning models by transforming the deep learning model which is represented as a computation graph. We aim to minimise the runtime cost on hardware devices by using an RL agent to choose a sequence of transformations and locations which mutate the graph. Recent work has aimed to apply reinforcement learning to computer systems with some success, especially with using model-free RL techniques. However, more recently, model-based methods has seen an increased focus of research as model-based reinforcement learning can be used to learn a model of the environment, that can be leveraged to train an agent inside the learned world-model---increasing sample efficiency. Furthermore, when using a hallucinogenic world model as the environment, rollouts can occur safely in parallel and, especially in systems environments, it circumvents the possible latency impact of stepping a system environment that can take orders of magnitude longer to perform an action compared to a video game emulator. This dissertation examines both the prior work for optimising deep learning models and the applicability of reinforcement learning to the problem.

\vspace*{\fill}
